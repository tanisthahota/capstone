{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b96801b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfc919a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client =chromadb.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76a17b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = chroma_client.create_collection(name = \"poem\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bce69943",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(\n",
    "    ids=[\"id1\", \"id2\"],\n",
    "    documents=[\n",
    "        \"This is a document about pineapple\",\n",
    "        \"This is a document about oranges\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b6fcecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': [['id1', 'id2']], 'embeddings': None, 'documents': [['This is a document about pineapple', 'This is a document about oranges']], 'uris': None, 'included': ['metadatas', 'documents', 'distances'], 'data': None, 'metadatas': [[None, None]], 'distances': [[1.0404009819030762, 1.2430799007415771]]}\n"
     ]
    }
   ],
   "source": [
    "results = collection.query(\n",
    "    query_texts=[\"This is a query document about hawaii\"], # Chroma will embed this for you\n",
    "    n_results=2 # how many results to return\n",
    ")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83f32c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted documents into Chroma ✅\n",
      "Shakespeare.\n",
      "Mount Everest is the tallest mountain in the world.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import ollama\n",
    "\n",
    "# Step 1: Define 10 sample documents\n",
    "documents = [\n",
    "    \"The capital of France is Paris.\",\n",
    "    \"Python is a popular programming language for AI research.\",\n",
    "    \"The Great Wall of China is visible from space.\",\n",
    "    \"Water boils at 100 degrees Celsius.\",\n",
    "    \"The Pacific Ocean is the largest ocean on Earth.\",\n",
    "    \"Mount Everest is the tallest mountain in the world.\",\n",
    "    \"Shakespeare wrote Romeo and Juliet.\",\n",
    "    \"The human heart has four chambers.\",\n",
    "    \"Photosynthesis is how plants make food using sunlight.\",\n",
    "    \"Albert Einstein developed the theory of relativity.\"\n",
    "]\n",
    "\n",
    "doc_ids = [f\"doc_{i}\" for i in range(len(documents))]\n",
    "\n",
    "# Step 2: Embedding model\n",
    "embedder = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Step 3: Insert docs into Chroma\n",
    "embeddings = embedder.encode(documents).tolist()\n",
    "collection.add(\n",
    "    documents=documents,\n",
    "    embeddings=embeddings,\n",
    "    ids=doc_ids\n",
    ")\n",
    "\n",
    "print(\"Inserted documents into Chroma ✅\")\n",
    "\n",
    "# ----------- RAG Pipeline -----------\n",
    "\n",
    "def rag_query(query, top_k=3):\n",
    "    # Step 4: Embed query\n",
    "    query_emb = embedder.encode([query]).tolist()\n",
    "    \n",
    "    # Step 5: Retrieve from Chroma\n",
    "    results = collection.query(\n",
    "        query_embeddings=query_emb,\n",
    "        n_results=top_k\n",
    "    )\n",
    "    retrieved_docs = results[\"documents\"][0]\n",
    "    \n",
    "    # Step 6: Construct prompt for LLM\n",
    "    context = \"\\n\".join(retrieved_docs)\n",
    "    prompt = f\"\"\"You are a helpful assistant. \n",
    "Use the following context to answer the question.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {query}\n",
    "Answer:\"\"\"\n",
    "\n",
    "    # Step 7: Call Gemma via Ollama\n",
    "    response = ollama.chat(\n",
    "        model=\"gemma3:4b\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response[\"message\"][\"content\"]\n",
    "\n",
    "# Example\n",
    "print(rag_query(\"Who wrote Romeo and Juliet?\"))\n",
    "print(rag_query(\"What is the tallest mountain?\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4bfaee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
